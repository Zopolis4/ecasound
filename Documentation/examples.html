<html>
<head>
<title>Ecasound Examples</title>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="author" lang="en" content="Kai Vehmanen">
<link rel="stylesheet" type="text/css" href="style_ecasound.css" />
</head>

<br />
<hr />

<center><h2> Ecasound Examples - The Best Place to Get Started with Ecasound</h2></center>

<hr />

<p>Remember to also check out the 
<a href="http://eca.cx/ecasound/Documentation/tutorials.html">Ecasound Tutorials and Articles</a>
[<a href="tutorials.html">alt link</a>]
page, the 
<a href="http://eca.cx/ecasound/Documentation/ecasound_manpage.html">ecasound(1)</a>
[<a href="ecasound_manpage.html">alt link</a>]
manpage, and
the <a href="http://eca.cx/ecasound/Documentation/users_guide/html_uguide/users_guide.html">
Ecasound User&rsquo;s Guide</a>.</p>

<p>
The console mode user-interface, <i>ecasound</i>, is 
used in all the following examples. Other ecasound frontends 
may use a different syntax, but the basic principles are the 
still the same as long as ecasound is used as the backend
engine.
</p>

<p>
Version note: sections describing recently introduced features
have a note about the minimum required version.
</p>

<ul>
<li><a href="#fconversions">Format Conversions</a></li>
<li><a href="#rtplayback">Realtime Outputs (playing to a sound device)</a></li>
<li><a href="#rtrecording">Realtime Inputs (recording from a sound device)</a></li>
<li><a href="#rtjack">Use with JACK audio server</a></li>
<li><a href="#effects">Effect Processing</a></li>
<li><a href="#controllers">Using controller sources with effects</a></li>
<li><a href="#multitrack">Multitrack Recording</a></li>
<li><a href="#mixing">Mixing</a></li>
<li><a href="#cutcopypaste">Cut, Copy and Paste</a></li>
<li><a href="#audio_ops">Manimulating objects - looping, reversing, ...</a></li>
<li><a href="#multichannel">Multichannel Processing</a></li>
<li><a href="#srouting">Signal Routing through External Devices</a></li>
<li><a href="#presets">Presets and LADSPA Effect Plugins</a></li>
<li><a href="#midi-io">More with MIDI</a></li>
<li><a href="#tonegeneration">Tone generation</a></li>
<li><a href="#piping">Piping data from other processes</a></li>
<!-- <li></li> -->
</ul>

<hr />

<!-- ###  new section ### -->
<p class="examplecat">
<a name="fconversions"><b>Format Conversions</b></a>
</p>
<ol>
<p>
<li> ecasound -i:somefile.wav -o:somefile.cdr</li>
<li> ecasound -i somefile.wav -o somefile.cdr</li>
</p><p>
These do the same thing, convert <i>somefile.wav</i> to
<i>somefile.cdr</i>. As no chains are specified, <i>default</i>
chain is used. 
</p><p>
<li> ecasound -a:1,2 -i somefile.wav -a:1 -o somefile.cdr -a:2 -o somefile.mp3</li>
</p><p>
This is not a very useful example, but hopefully helps to understand 
the way chains work. First, two new chains <i>1</i> and <i>2</i>
(you can also use strings: '-a:some_name_with_no_whitespaces,some_other_name') are created.
They are now the active chains. After this, input <i>somefile.wav</i> is
connected to both these chains. The rest follows the same scheme.
Chain '1' is set active and output <i>somefile.cdr</i> is
attached to it. In the same way, <i>somefile.mp3</i> is attached to
chain '2'. 
</p><p>
<li> ecasound -c -i somefile.wav -o somefile.cdr</li>
</p><p>
Like before, but ecasound is now started in interactive mode. 
</p>
</ol>

<!-- ###  new section ### -->
<p class="examplecat">
<a name="fcresampling"><b>Format Conversions - Resampling</b></a>
</p>

<ol>

<li> ecasound -f:16,2,96000 -i resample,auto,foo44100.wav -o bar96k.wav</li>
<li> ecasound -f:16,2,44100 -i resample,auto,bar96k.wav -o foo44100.wav</li>
<li> ecasound -f:16,2,44100 -i resample-hq,48k,foo48k.wav -o bar.wav</li>
<li> ecasound -f:16,2,44100 -i resample,96k,third.raw -o foo44100.wav</li>

<p>
To do resampling, a special 'resample' input type must be used. 
In the first example above, the 44100Hz file <i>foo44100.wav</i> is 
resampled to 96kHz and the result is written to <i>bar96k.wav</i>.
In the second example the reverse is done, sample rate is converted
from 96khz to 44100Hz. In the last example, the from rate has to
be specified explicitly as raw audio files do not contain the 
necessary header information.
</p>

<p>
In the last example we do a 48000Hz to 44100Hz conversion using
the 'resample-hq' input type. If Ecasound was built with support
for the libsamplerate package, 'resample-hq' selects
the high-quality conversion mode. In this mode the conversion
process requires more CPU power, but the results are of
higher quality. Using libsamplerate also improves quality 
of the default 'resample' mode.
</p>

</ol>

<!-- ###  new section ### -->
<p class="examplecat">
<a name="rtplayback"><b>Realtime Outputs (playing to a sound device)</b></a>
</p>
<ol>
<p>
Following are examples of recording from, and playing back to,
ALSA sound device (Linux):
</p>
<li> ecasound -i somefile.mp3 -o alsa</li>
<li> ecasound -i somefile.mp3 -o alsahw,0,0</li>
<li> ecasound -i somefile.mp3 -o alsaplugin,0,0</li>
<li> ecasound -i somefile.mp3 -o alsa,soundcard_name</li>
</p><p>
ALSA sound subsystem provides multiple ways to select which audio
device to use, and how it is accessed. A plain "alsa" will use the default 
ALSA sound device (depends on system configuration). Alternatively you can either 
specify "alsahw" (to indicate you want use the ALSA direct hardware interface), 
or "alsaplugin" (to utilize the ALSA plugin layer). Both accept card number and 
device number as parameters. Optionally also subdevice can be given. 
The plugin layer is able to handle some type conversions automatically. 
Yet another option is to specify the ALSA device name ('soundcard_name').
The device name must be defined in the ALSA configuration files (either in
~/.asoundrc or in the global settings file). 
</p>
<p>
Following are examples of recording from, and playing back to,
OSS sound device (Linux, BSDs and many other OS'es):
</p>
<li> ecasound somefile.wav</li>
<li> ecasound -i somefile.wav</li>
<li> ecasound -i:somefile.wav </li>
<li> ecasound -i somefile.wav -o /dev/dsp</li>
</p><p>
If you haven't touched your <b>~/.ecasound/ecasoundrc</b> configuration file,
these should all do the same thing, output <i>somefile.wav</i> to
<i>/dev/dsp</i> using the <i>default</i> chain. If no inputs are 
specified, ecasound tries to use the first non-option argument on the
command line as a default input. If no chains are specified, the chain
'default' is created and set active. If no outputs are specified,
the default-output defined in <b>~/.ecasound/ecasoundrc</b> is used. 
This is normally <i>/dev/dsp</i>.
</p>
<p>
See also section on <a href="#rtjack">JACK</a> below.
</p>
</ol>

<!-- ###  new section ### -->
<p class="examplecat">
<a name="rtrecording"><b>Realtime Inputs (recording from a sound device)</b></a>
<p>
<ol>
<li> ecasound -i:/dev/dsp0 -o somefile.wav</li>
<li> ecasound -i:alsa -o somefile.wav -c</li>
<li> ecasound -i alsahw,1,0 -o somefile.wav</li>
</p>
<p>
These are simple examples of recording. When recording, it may
be useful to run ecasound in interactive mode (-c).
</p>
<p>
See also section on <a href="#rtjack">JACK</a> below.
</p>
</ol>

<!-- ###  new section ### -->
<p class="examplecat">
<a name="rtjack"><b>Use with JACK audio server</b></a>
</p>

<ol>
<p>
<li>ecasound -i foo.wav -o jack_alsa</li>
<li>ecasound -i foo.wav -o jack</li>
</p>
<p>
This will create a separate JACK output port for each channel
of foo.wav, and automatically connect these Ecasound ports to
the ALSA PCM output ports in the JACK server.  The second
example will create JACK output ports, but does not establish
any connections (you have to do this yourself with jack_connect,
qjackconnet, qjackctl, or other similar tool).
</p>
<p>
<li>ecasound -c -i foo.wav -o jack_alsa -G:jack,eca_slave,recv</li>
</p>
<p>
Like in previous examples, but the ecasound client name (as shown
to other JACK clients) is set to "eca_slave", and ecasound is 
configured to react to incoming transport changes (play, stop,
seek, etc). By default ecasound both sends and reacts to 
transport events.
</p>
</ol>

<!-- ###  new section ### -->
<p class="examplecat">
<a name="effects"><p><b>Effect Processing</b></a></p>
<ol>
<p> 
Ecasound is an extremely versatile tool when it comes to effect
processing. After all, it was originally programmed for non-realtime
dsp processing. Because of this, these examples just scratch 
the surface.
</p><p>
<li> ecasound -i somefile.mp3 -o /dev/dsp -ea:120</li>
<li> ecasound -a:default -i somefile.mp3 -o /dev/dsp -ea:120</li>
<p>
Let's start with a simple one. These do the same thing: mp3 input, 
OSS output and an amplify effect, which amplifies the signal
by 120%, are added to the default chain. 
</p><p>
<li> ecasound -i somefile.mp3 -o /dev/dsp -etr:40,0,55 -ea:120</li>
</p><p>
Like the previous example, but now a reverb effect, with a delay of 40
milliseconds, surround disabled and mix-% of 55, is added to chain 
before the amplify effect. In other words the signal is first
processed with the reverb and then amplified. This way you can add 
as many effects as you like. If you ran out of CPU power, you can
always use output to a file.
</p><p>
<li> ecasound -a:1,2 -i somefile.mp3 -a:all -o /dev/dsp \<br>
<ul>
     -a:1 -etr:40,0,55 -ea:120 \<br>
     -a:2 -efl:400
</ul></li>
</p>
<p>
Ok, let's do some parallel processing. This time two chains are
created and the input file is assigned to both of them. The output
file is assigned to a special chain called <b>all</b>. '-a:1,2'
would also work. This way we can use one signal in multiple chains 
and process each chains with different effects. You can create as many
chains as you want.
</p>
</ol>

<!-- ###  new section ### -->
<p class="examplecat">
<a name="controllers"><b>Using controller sources with effects</b></a></p>
<ol>
<p>
<li> ecasound -i somefile.wav -o alsa -ef3:800,1.5,0.9 -kos:1,400,4200,0.2,0 -kos:2,0.1,1.5,0.15,0 </li>
<li> ecasound -i somefile.wav -o alsa -ef3:800,1.5,0.9 -km:1,400,4200,74,1 -km:2,0.1,1.5,71,1</li>
</p>
<p>
The first example uses two sine oscillators
('-kos:parameter,range_low,range_high,speed_in_Hz,initial_phase')
to control a resonant lowpass filter. The cutoff frequency varies
betweeen 400 and 4200 Hz, while resonance varies between 0.1 and 1.5.
The initial phase is 0 (times pi). The second example uses MIDI continuous
controllers
('-km:parameter,range_low,range_high,controller_number,midi-channel')
as controller sources. The ranges are the same as in the
in first example. Controller numbers used are 74 (cutoff) and 71
(resonance). In other words you can use your synth's cutoff and
resonance knobs.
</p>
<p>
It's also possible to control controllers with other controllers 
using the '-kx' option. Normally when you add a controller,
you're controlling the last specified chain operator. 
'-kx' changes this. Let's take an example:
</p>
<p>
<li> ecasound -i file.wav -o alsa -ea:100 -kos:1,0,100,0.5,0 -kx -kos:4,0.1,5,0.5,0
</p>
<p>
Same as before, but now another 0.5Hz sine oscillator is controlling 
the frequency of the first oscillator.
</p>
<p>
<li>ecasound -i file.wav -o alsa -ef3:1000,1.0,1.0 -kos:1,500,2000,1,0 \<br>
				 -kos:2,0.2,1.0,0.5,0  \<br>
				 -kx -km:1,0.1,1.5,2,1</li>
</p>
<p>
Ok, let's get real whacky. Here a 1Hz sine oscillator is assigned to
the cutoff frequency, while other controller is controlling resonance.
Now we add a MIDI-controller, that controls the second sine
oscillator.
</p>
</ol>

<!-- ###  new section ### -->
<p class="examplecat">
<a name="multitrack"><b>Multitrack Recording</b></a></p>
<ol>
<p>
<li> ecasound -c -b:256 -r -f:16,2,44100 \<br>
<ul>
	      -a:1 -i monitor-track.wav -o alsa \<br>
  	      -a:2 -i alsa -o new-track.wav
</ul></li>
</p>
<p>
It really is this simple. To minimize syncronization problems,
a small buffersize is set with '-b:buffer_size_in_samples'.
This time I set it to 256 samples. To ensure flawless recording,
runtime priority is risen with '-r'. Then a default sample format
is set with '-f:bits,channels,sample_rate'. Now all that's left
is to specify two chains: one for monitoring and one for recording.
When using the above command, you need to have some way of monitoring 
the signal that's been recorded. A common way is to enable
hw-monitoring (unmute/adjust the line-in level from your mixer app). 
If you want to use ecasound for monitoring, you have to add a separate 
chain for it:</p>
<p>
<li> ecasound -c -b:256 \<br>
<ul>
        -a:1 -i monitor-track.wav \<br>
        -a:2,3 -i alsa \<br>
        -a:2 -o new-track.wav \<br>
        -a:1,3 -o alsa<br>
</ul></li>
</p>
<p>
One thing to note that there are some differences in how OSS soundcard
drivers handle full-duplex (playback and recording at the same time)
operation. Some drivers allow the same device to be opened multiple
times (like in above example we open 'alsa' once for recording 
and once for playback.
</p>
<p> 
You can always do test recordings until you find the optimal volume
levels (using the soundcard mixer apps and adjusting source volume),
but ecasound offers a better way to do this. This is a bit ugly,
but what's most important, it works in text-mode:</p>
<p>
<li> ecasound -c -f:16,2,44100 -a:1 -i /dev/dsp0 -o /dev/dsp3 -ev</li>
</p>
<p>Basicly this just records from one OSS input, puts the signal through
an analyze ('-ev') effect and outputs to an OSS output. The secret
here is that you can get volume statistics with the <u>estatus</u> (or
<u>es</u>) command in interactive mode. Newer ecasound versions (1.8.5
and newer) come with 'ecasignalview', which is a standalone app that
can monitor signal level in realtime.
</p>
</ol>
<!-- ###  new section ### -->
<p class="examplecat">
<a name="mixing"><b>Mixing</b></a></p>
<ol>
<p>Here's a few real-life mixdown examples.</p>
<p>
<li> ecasound -c \<br>
<ul>
     -a:1 -i drums.wav \<br>
     -a:2 -i synth-background.wav \<br>
     -a:3 -i bass-guitar_take-2.ewf \<br>
     -a:4 -i brass-house-lead.wav \<br>
     -a:all -o alsa
</ul></li>
</p>
<p>
First of all, interactive-mode is selected with '-c'. Then 
four inputs (all stereo) are added. All four chains are then assigned
to one output, which this time is the soundcard (alsa). That's
all.
</p>
<p>
<li> ecasound -c -r \<br>
<ul>
     -a:1 -i drums.wav -ea:200 \<br>
     -a:2 -i synth-background.wav -epp:40 -ea:120 \<br>
     -a:3 -i bass-guitar_take-2.ewf -ea:75 \<br>
     -a:4 -i brass-house-lead.wav -epp:60 -ea:50 \<br>
     -a:1,2,3,4 -o loop,1 \<br>
     -a:5,6 -i loop,1 \<br>
     -a:5 -o alsa \<br>
     -a:6 -o current-mix.wav<br>
</ul></li>
</p>
<p>
This second example is more complex. The same inputs are used, but
this time effects (amplify '-ea:mix_percent' and normal
pan '-epp:left_right_balance') are also used. Additionally we want
to route the full mix to both the soundcard and to a file. We can
accomplish this by using a virtual loop device. Here the first four 
chains are routed to a loop device 'loop,1', which again feeds the 
audio to both the soundcard 'alsa' and to a WAVE file 
'current-mix.wav'. In this example, runtime priority is also
risen with '-r' (requires root privileges).
</p>
</ol>

<!-- ###  new section ### -->
<p class="examplecat">
<a name="cutcopypaste"><b>Cut, Copy and Paste</b></a></p>
<ol>
<p>
<li> ecasound -i bigfile.wav -o part1.wav -t:60.0</li>
<li> ecasound -i bigfile.wav -y:60.0 -o part2.wav</li>
</p>
<p> 
Here's a simple example where first 60 seconds of 
bigfile.wav is written to part1.wav and the rest to 
part2.wav. If you want to combine these files back to 
one big file:
</p>
<p>
<li> ecasound -i part2.wav -o part1.wav -y:500</li>
</p>
part2.wav is appended to part1.wav.
</p>
</ol>

<!-- ###  new section ### -->
<p class="examplecat">
<a name="audio_ops"><b>Manimulating objects - looping, reversing, ...</b></a></p>
<ol>
<p>
To continuously loop an audio file, you can use 'audioloop':
</p>
<li> ecasound -i audioloop,drumloop.wav -o alsa</li>
<p>
To run the loop for 65.0secs, you can use '-t':
</p>
<li> ecasound -i audioloop,drumloop.wav -o alsa -t:65.0</li>
<p>
To play an audio file in reserve:
<li> ecasound -i reverse,drumloop.wav -o alsa</li>
</p>
</ol>

<!-- ###  new section ### -->
<p class="examplecat">
<a name="multichannel"><b>Multichannel Processing</b></a></p>
<ol>
<p>You need to worry about channel routing only if input and 
output channel counts do not match. Here's how you 
divide a 4-channel audio file into 4 mono files.
</p>
<li> ecasound -a:1,2,3,4 -i 4-channel-file.raw \<br>
<ul>
 	    -a:1 -f:16,1,44100 -o mono-1.wav \<br>
 	    -a:2 -f:16,1,44100 -o mono-2.wav -chcopy:2,1 \<br>
 	    -a:3 -f:16,1,44100 -o mono-3.wav -chcopy:3,1 \<br>
 	    -a:4 -f:16,1,44100 -o mono-4.wav -chcopy:4,1
</ul></li>
<p>
Version note: '-chcopy' was introduced in version 2.4.5. In earlier versions
'-erc' provides similar functionality.
</p>
</ol>

<!-- ###  new section ### -->
<p class="examplecat">
<a name="srouting"><b>Signal Routing through External Devices</b></a></p>
<ol>
<p>
<li> ecasound -c -b:128 -r -f:16,2,44100 \<br>
<ul>
	      -a:1 -i source-track.wav -o /dev/dsp3 \<br>
  	      -a:2 -i /dev/dsp0 -o target-track.wav
</ul></li>
</p>
<p>
So basicly, this is just like multirack recording. The only difference
is that realtime input and output are externally connected.
</p>
</ol>

<!-- ###  new section ### -->
<p class="examplecat">
<a name="presets"><b>Presets and LADSPA Effect Plugins</b></a></p>
<ol>
<p>
<li> ecasound -i null -o alsa -el:sine_fcac,440,1</li>
</p><p>
This produces a 440Hz sine tone (great for tuning your instruments!).
For the above to work, LADSPA SDK needs to be installed (see 
<a href="http://www.ladspa.org">www.ladspa.org</a>).
</p>

<p>
<li> ecasound -i:null -o:alsa -el:sine_fcac,880,1 -eemb:120,10 -efl:2000</li>
</p>
<p>
This results in audible metrome signal with tempo of 120BPM. Now 
the syntax might look a bit difficult for everyday use. Luckily
ecasound's preset system will help in this situation. You can get the
same exact result with:
</p>
<p>
<li> ecasound -i:null -o:alsa -pn:metronome,120</li>
</p>
<p>
See the file 'effect_presets' for a list of available effect
presets. By default, location of this file is '/usr/local/share/ecasound/effect_presets'.
</p>
</ol>


<!-- ###  new section ### -->
<p class="examplecat">
<a name="midi-io"><b>More MIDI examples</b></a></p>
<ol>
<p>
<li> ecasound -i somefile.wav -o alsa -efl:400 -km:1,400,4200,74,1</li>
</p>
<p>
The above is a simple example how MIDI is used to control an effect -
here the low-pass filter -efl. The above uses OSS rawmidi access, which
is equivalent to adding -Md:rawmidi,/dev/midi to the command line.
To do the same with ALSA, the syntax is as follows:</p>
<p>
<li> ecasound -i somefile.wav -o alsa -efl:400 -km:1,400,4200,74,1 -Md:rawmidi,/dev/snd/midiC0D0</li>
<li> ecasound -i somefile.wav -o alsa -efl:400 -km:1,400,4200,74,1 -Md:alsaseq,80:1</li>
<li> ecasound -i somefile.wav -o alsa -efl:400 -km:1,400,4200,74,1 -Md:alsaseq,KMidimon</li>
</p>
<p>
The first one uses the ALSA rawmidi interface and opens an
ALSA device (card 0, device 0) for raw MIDI I/0. The second
example uses the ALSA sequencer API, which is more powerful as 
you can route MIDI packets from and to other applications 
supporting the sequencer API. "80,1" and "KMidimon" are sequencr ports 
to which ecasound should connect. You can use the "aconnect" (part 
of alsa-utils) tool to list all available sequencer ports.
</<p>
<p>
Version note: For ALSA sequencer support, you need ecasound 2.4.3 or
newer.
</p>
</ol>

<!-- ###  new section ### -->
<p class="examplecat">
<a name="tonegeneration"><p><b>Tone generation</b></a></p>
<ol>
<p> 
Ecasound has a few tone generation primitives. These are mainly
intended for testing, but can have other uses as well. For a more
versatile set of tone generators, one can utilize the various
LADSPA plugins. Below are examples of both:
</p>
<p>
A infinite sine tone of 880Hz, played out to the default ALSA
sound device.
</p>
<li> ecasound -i tone,sine,880 -o alsa</li>
<p>A sine tone of 440Hz with length of exactly 22.25secs. The
second example is similar, but length of sine tone is given
as samples (88200 in this case).
</p>
<li> ecasound -i tone,sine,440,22.25 -o alsa</li>
<li> ecasound -i tone,sine,880,88200sa -o alsa</li>

<p>
Version note: 'tone' audio object type was added to ecasound 
version 2.5.0.
</p>
</ol>

<!-- ###  new section ### -->
<p class="examplecat">
<a name="piping"><b>Piping data from other processes</b></a></p>
<ol>
One example of how audio can be piped to ecasound:
<p>
<li> mpg123 -s sometune.mp3 | ecasound -i:stdin -o alsa</li>
</p><p>
The above sends the output of mpg123 to standard output (-s option) and 
reads it from standard input with ecasound (-i:stdin option), and
plays in out through the default ALSA PCM device. Similarly 'stdout'
can be used to pipe data out from ecasound.
</p>
</ol>

<hr />
<p>Back to <a href="index.html">index</a>.</p>
<hr />

<!-- ###  end ### -->

<br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br
/><br /><br /><br /><br /><br /><br /><br /><br /><br /><br />
<br/><br /><br /><br />

</body>
</html>
