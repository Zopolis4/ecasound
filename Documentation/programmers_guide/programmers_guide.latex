\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage{html}
\hfuzz=4pt % don't fuss when less than 4pt
\input{/usr/share/yodl/xlatin1.tex}
\setlength{\parskip}{3mm} % height between par
\setlength{\parindent}{0mm} % no par indent

\bodytext{link="#662a00" vlink="#666655" bgcolor="#ffffff"}

\title{Ecasound Programmer's Guide}
\author{Kai Vehmanen}
\date{03102001}
\begin{document}

\maketitle
\tableofcontents 
\clearpage

\section{Preface}
This document describes how ecasound library works, how to use it,
how to extend and add features to it and so on. Before reading this
document, you should first look at other available documentation
(especially \texttt{ecasound users's guide}).

Unlike most web pages, this document really is under construction. :)



\section{General guidelines}


\subsection{Design and programming}
\subsubsection{Open and generic design}
Over the years ecasound's core design has been revised many times.
After rewriting some code sections hundreds of times, you start
to appreciate genericity. :) Although specific use-cases are used
for testing new ideas, they are just design aids.

\subsubsection{Object-orientation}
Ecasound is written in C++ (as specified in 1997 ANSI/ISO C++ standard). 
Because C++ language itself doesn't force you to follow OO-principles, 
I often use Eiffel language as a reference when designing classes and 
routines.

\subsubsection{Data hiding} 
This OO-feature deserves to be mentioned separately. Whenever 
possible, I always try to hide the actual data representation. 
This allows you to make local implementation changes without
affecting other parts of the code base. One thing I've especially 
tried to avoid is excessive use of pointer magic.

\subsubsection{Design by contract} 
Design by contract means that when you write a new routine,
in addition to the actual code, you also describe routine's 
behaviour as accurately as possible.

Routine must specify all requirements and assumptions. 
If the caller violates this specification, routine is not 
responsible for the error. This means that routine mustn't
check argument validity. This must be done by the caller.

Routine should also specify, what conditions are true when
returning to the caller. By doing this, routine ensures that
it works correctly and calling routine knows what has been
done.

Ideally, these conditions prove that the routine works correctly. 
The benefits of this approach should be clear. When you call 
a well-defined routine, a) you know what parameter values it 
accepts, b) you know what it does and c) if errors occur, 
it's easier to pinpoint the faulty routine. In practice this is 
done by using comments and pre/postconditions. As C++ doesn't 
directly support pre/postconditions, I've simulated them using
the class DEFINITION\_BY\_CONTRACT from kvutils package and with 
standard assert() calls.

\subsubsection{Routine side effects}
I try to make a clear distinction between routines that 
have side-effects (=methods, processors, modifiers; routines that
change object's state) and const routines (=functions, observers).

\subsubsection{Sanity checks}
Sanity checks are done only to prevent crashes. All effects
and operators happily accept "insane" parameters. For instance 
you can give -100.0\% to the amplifier effect. This of course 
results in inverted sample data. I think this a reasonable 
approach. After all, ecasound is supposed to be a tool for creative
work and experimenting. It's not meant for e-commerce. ;)

\subsubsection{Error handling}
Two specific things worth mentioning: First, the standard UNIX-style 
error handling, where functions performing actions return an integer 
value, is \emph{not} used in ecasound. As described in the above section 
\emph{Routine side effects}, all routines are either modifiers or
observers, not both. So when using ecasound APIs, you first perform an
action (modifying function), and then afterwards check what happened
(using an observer function).

\subsubsection{Exceptions}
C++ exceptions are used in ecasound. Exception based error
handling has its problems, but in some cases it is clearly the best
option. Using exceptions for anything other than pure exception
handling is to be avoided at all cost. And when exceptions are used,
their use must be specified in function prototypes. This is important,
as clients need to know what exceptions can be thrown. All in all, 
use of exceptions should be carefully planned.

A list of specific cases where exceptions are used follows:
\begin{description}
\item[AUDIO\_IO - open()]
This method is used for initializing external connections (opening
files or devices, loading shared libraries, opening IPC connections). 
It's impossible to know in advance what might happen. In many cases it
is also useful to get more verbose information about the problem 
that caused open() to fail. Throwing an exception is an excellent way
to achieve this.

\item[ECA\_CHAINSETUP - enable()]
\item[ECA\_CHAINSETUP - load\_from\_\texttt{}, save() and save\_to\_\texttt{}]
\item[ECA\_SESSION - constructor]

\end{description}


\subsection{Coding style}
\subsubsection{General guide lines}
Variable names are all lower case and words are separated with
underscores (int very\_long\_variable\_name\_with\_underscores). Class data
members are marked with \emph{\_rep} postfix. Data members which are
pointers are marked with \emph{\_repp}. Index-style short variable names 
(\emph{n}, \emph{m}, etc.) are only used in local scopes. Enum types 
have capitalized names (\emph{Some\_enum}).

\subsubsection{Package specific}
\begin{description}
\item[libecasound, ecasound, ecatools, libkvutils]
Class names are all in upper case and words separated with underscores
(class ECA\_CONTROL\_BASE). This a standard style in Eiffel programming.

\item[libqtecasound, qtecasound, ecawave]
Qt-style is used when naming classes (class QELevelMeter), otherwise
same as above.
\end{description}


\subsection{Physical level organization}
Ecasound libraries and applications are divided into \emph{distribution 
packages}, \emph{directories} and \emph{file groups}. 

\subsubsection{Distribution packages}
As an example, \emph{ecasound} and \emph{qtecasound} are distributed as separate
packages. This decision has been made because a) they are clearly 
independent, b) they have different external dependencies, and c)
they address different target uses. 

\subsubsection{Directories}
It's convenient to organize larger sets of source code into separate
directories. For instance in ecasound, \emph{libecasound} and
\emph{ecatools} are in two separate directories.

\subsubsection{File groups}
Although files are divided in directories and subdirectories, 
there's still a need to logically group a set of source files based
on their use and role in the overall design. As the use of C++ 
namespaces is very limited in ecasound (to avoid portability
problems), filename prefixes are used for grouping files. Here's
a short list of commonly used prefixes. 

\begin{description}
\item[audioio*.\{cpp,h\}] 
Audio device and file input/output.
\item[audiofx*.\{cpp,h\}] 
Audio effects and other DSP-related code.
\item[audiogate*.\{cpp,h\}] 
Gate operators.
\item[eca-*.\{cpp,h\}] 
Core functionality.
\item[midi-*.\{cpp,h\}] 
MIDI input/output devices, handlers and controller code.
\item[osc-*.\{cpp,h\}] 
Oscillator and other controller sources.
\item[qe*.\{cpp,h\}] 
Generic prefix for files utilizing both Qt and ecasound libraries.
\item[samplebuffer-*.\{cpp,h\}] 
Routines and helper functions for processing audio data buffers.
\end{description}

You should note that these are just recommendations - there are no
strict rules on how files should be named.


\subsection{Documentation style}
Javadoc-style class documentation is the preferred style.
Class members can be documented either when they are declared (header
files), or when they are defined. Especially when specifying
complicated interfaces, it's better to put documentation in the
definition files. This way the header files remain compact and serve 
better as a reference. 

Here's a few general documentation guide lines:
\begin{description}
\item[Use of 3rd person] 
"Writes samples to memory." instead of "Write samples to memory."
\item[Sentences start with a verb]
"Writes samples to memory." instead of "Samples are written to memory."
\item[This instead of the]
"Get controllers connected to this effect." instead of "Get controllers connected to the effect.
\end{description}


\subsection{Versioning}
All ecasound releases have a distinct version number. To emphasize the
difference between stable and development releases, stable versions
have an even, and devel versions have an odd minor version number. In
addition, devel versions are marked with 'devXX'. For instance, you
could have development releases 0.1dev1, 0.1dev2 and 0.1dev3. When the 
development reaches a stable status, 0.2 is released. After this, a
new development series will start (0.3dev1, and so on).

Separation between development and stable releases is very important,
because it affects library versioning. The idea is that all library
interfaces are versioned separately with libtool. If during
development changes are made to the public interfaces, a new interface
version is created. The new interface version won't be frozen until the 
next stable version. After this, no changes to the interface (affects
both at binary and source level) are allowed. If these changes must be 
made, a new interface version must be created. It's important to note
that interface compatibility is not guaranteed between development
releases. So if you are linking apps against development versions of
ecasound libraries, you must be prepared for interface changes.

All changes in the public interfaces are documented in library
specific \emph{ChangeLog} files. These files are usually located in the
top-level source directory.



\section{How ecasound works?}


\subsection{Common use-cases}
Here's some common cases how ecasound can be used.

\subsubsection{Simple non-interactive processing}
One input is processed and then written to one output. This includes effect 
processing, normal sample playback, format conversions, etc.

\subsubsection{Multitrack mixing}
Multiple inputs are mixed into one output.

\subsubsection{Realtime effect processing}
There's at least one realtime input and one realtime output.
Signal is sampled from the realtime input, processed and
written to the realtime output.

\subsubsection{One-track recording}
One input is processed and written to one or more outputs.

\subsubsection{Multitrack recording}
The most common situation is that there are two separate
chains. First one consists of realtime input routed to a
non-realtime output. This is the recording chain. The
other one is the monitor chain and it consists of one or
more non-realtime inputs routed to a realtime output.
You could also route your realtime input to the monitoring
chain, but this is not recommended because of severe
timing problems. To synchronize these two separate chains,
ecasound uses a special multitrack mode (which should be
enabled automatically).

\subsubsection{Recycling a signal through external devices}
Just like multirack recording. The only difference is
that realtime input and output are externally
connected.


\subsection{Signal flow}
This is simple. A group of inputs is routed to a group of chains.
Audio data is processed in the chains and afterwards routed to 
a group of outputs. Using internal loop devices, it' also possible to 
route signals from one chain to another. It's also possible to assign
inputs and outputs to multiple chains.


\subsection{Control flow}
\subsubsection{Passive operation}
When ecasound is run in passive mode, the program flow is simple.
A ECA\_SESSION object is created with suitable parameters, it is
passed to a ECA\_PROCESSOR object and that is all. 
Processing is started with the exec() member function of 
ECA\_PROCESSOR. After processing is finished, exec() returns
to the caller.

Another way to do passive processing is to create a ECA\_CONTROL 
object and use it to to access and modify the ECA\_SESSION object 
before passing it to ECA\_PROCESSOR.

\subsubsection{Interactive operation}
In interactive mode, everything is done using the interface provided
by ECA\_CONTROL. This is when things get complex:

ECA\_SESSION object can contain many ECA\_CHAINSETUP objects, but
only one of them can be active. On the other hand it is possible
that there are no chainsetups. If this is the case, about the
only thing you can do is to add a new chainsetup. 

One chainsetup at a time can be \emph{selected}. In this state
the chainsetup can be edited using the methods provided by
ECA\_CONTROL. Only one setup at a time can be \emph{connected} to
the engine (ie. actual use). Trying to connect an invalid 
chainsetups will fail. A valid chainsetup has at least one 
input-output pair connected to the same chain.

ECA\_CHAINSETUP can be...
\begin{description}

\item[not selected] - can't be accessed from ECA\_PROCESSOR
\item[selected, invalid] - can be edited (files and devices are not opened)
\item[selected, valid] - can be connected (files and devices are not opened)
\item[connected] - ready for processing (files and devices are opened before connecting)

\end{description}

ECA\_PROCESSOR status is one of...
\begin{description}

\item[not\_ready] - ECA\_SESSION object is not ready for processing or
ECA\_PROCESSOR hasn't been created
\item[running] - processing
\item[stopped] - processing hasn't been started or it has been stopped
before completion
\item[finished] - processing has been completed
\item[error] - an error has occured during prosessing
\end{description}

\subsection{Class descriptions}

The primary source for class documentation is header files.
A browsable version of header documentation is at
\texttt{www.wakkanet.fi/\textasciitilde kaiv/ecasound/Documentation/doxygen\_pages.html}
Anyway, let's look at the some central classes.


\subsubsection{Core} 
\paragraph{ECA\_PROCESSOR} 
ECA\_PROCESSOR is the actual processing engine. It is initialized with
a pointer to a ECA\_SESSION object, which has all information needed at
runtime. Processing is started with the exec() member function and
after that, ECA\_PROCESSOR runs on its own. If the interactive mode is
enabled in ECA\_SESSION, ECA\_PROCESSOR can be controlled using the
ECA\_CONTROL class. It offers a safe way to control ecasound.
Another way to communicate with ECA\_PROCESSOR is to access the
ECA\_SESSION object directly.

\paragraph{ECA\_SESSION} 
ECA\_SESSION represents the data used by ecasound. A session contains
all ECA\_CHAINSETUP objects and general runtime settings (iactive-mode,
debug-level, etc). Only one ECA\_CHAINSETUP can be active at a time. To
make it easier to control how threads access ECA\_SESSION, only
ECA\_PROCESSOR and ECA\_CONTROL classes have direct access to
ECA\_SESSION data and functions. Other classes can only use \emph{const}
members of ECA\_SESSION. 

\paragraph{ECA\_CONTROL} 
ECA\_CONTROL represents the whole public interface offered by 
ecasound library. It also has a simple command interpreter 
(interactive-mode) that can used for controlling ecasound. 


\subsubsection{Data objects}

\paragraph{SAMPLEBUFFER}
Basic unit for representing sample data. The data type used to 
represent a single sample, valid value range, channel count, global 
sampling rate and system endianess are all specified in 
"samplebuffer.h" and "sample\_specs.h".

\paragraph{DEBUG}
Virtual interface class for ecasound's debugging subsystem. Ecasound 
engine sends all debug messages to an instance of this class. The actual 
implementation can be done in many ways. For example in the console mode
user-interface of ecasound, TEXTDEBUG class implements the DEBUG
interface. It sends all messages that have a suitable debug 
level to the standard output stream. On the other hand, in qtecasound 
DEBUG is implemented using a Qt widget. New DEBUG implementations can
be registered at runtime with the \emph{attach\_debug\_object()} call
(declared in eca-debug.h).


\subsubsection{Object maps}
Object maps are a central repositories for commonly used objects.
When object is registered to a map, a regular expression is attached 
to it. When object map receives a request for a new object, it 
goes through all registered regular expressions, and returns an 
object attached to the matching expression. Object maps can also provide
a list of all registered objects. 

This system may sound a bit complex, but in practise it is quite
simple and makes a lot of things more easier. For instance, when
adding new object types to the library, you only have to add a call
which registers the new object; no need to modify any other part of 
the library. It also makes it possible to add new types at runtime. For
instance, an application linked against libecasound might add its own
custom object types on startup. All parts of libecasound can use the
custom objects, although they are not part of library itself.

All objects defined in libecasound are registered in the file
\emph{eca-static-object-maps.cpp}.

\paragraph{ECA\_OBJECT}
A virtual base class that represents one object. All classes deriving 
from ECA\_OBJECT can be registered to object maps.

\paragraph{ECA\_OBJECT\_MAP}
This is the basic object map implementation. It offers map services
for ECA\_OBJECT objects.

\paragraph{ECA\_PRESET\_MAP}
Special class that inherits from ECA\_OBJECT\_MAP. This class is used
for mapping instances of class PRESET.

\paragraph{ECA\_AUDIO\_OBJECT\_MAP}
A convenience class for mapping AUDIO\_IO objects. Handles the casting 
between ECA\_OBJECT<->AUDIO\_IO.

\paragraph{ECA\_CHAIN\_OPERATOR\_MAP}
A convenience class for mapping CHAIN\_OPERATOR objects. Handles the casting 
between ECA\_OBJECT<->CHAIN\_OPERATOR.

\paragraph{ECA\_CONTROLLER\_MAP}
A convenience class for mapping GENERIC\_CONTROLLER objects. Handles the casting 
between ECA\_OBJECT<->GENERIC\_CONTROLLER.

\paragraph{ECA\_LADSPA\_PLUGIN\_MAP}
A convenience class for mapping EFFECT\_LADSPA objects. Handles the casting 
between ECA\_OBJECT<->EFFECT\_LADSPA.




\section{Using ecasound from other programs}


\subsection{Console mode ecasound - {[}all languages{]}}
This is the easiest way to take advantage of ecasound features in your
own programs. You can fork ecasound, pipe commands to ecasound's
interactive mode or you can create chainsetup (.ecs) files and load
them to ecasound. You'll be able to do practically anything. The only 
real problem is getting information from ecasound. You'll have to
parse ecasound's ascii output if you want to do this. To make this 
a bit easier, ecasound offers the dump-* commands. These print
configuration and status info as formatted text strings (easier to
parse than normal output).


\subsection{Ecasound Control Interface - {[}C++, C, Python{]}}

Idea behind Ecasound Control Interface (ECI) is to take a subset of 
functionality provided by libecasound, write a simple API for it, and
port it to various languages. At the moment, at least C++, C and
Python implementations of the ECI API are available and part of the
main ecasound distribution. ECI is heavily based on ecasound's
interactive mode (EIAM), and the services it provides. 

Specific tasks ECI is aimed at:

\begin{itemize}
\item  1. automating (scripting in its traditional sense)
\item  2. frontends (generic / specialized)
\item  3. sound services to other apps
\end{itemize}


\subsection{Libecasound's ECA\_CONTROL class - {[}C++{]}}
By linking your program to libecasound, you can use the ECA\_CONTROL
class for controlling ecasound. This is a large interface class that
offers routines for controlling all ecasound features. It's easy
to use while still powerful. Best examples are the utils in ecatools 
directory (most of them are just a couple screenfuls of code). Also, 
qtecasound and ecawave heavily use ECA\_CONTROL. Here's a few lines of 
example code:

\begin{verbatim} 

--cut--
ECA_SESSION esession;
ECA_CONTROL ctrl (&esession);
ctrl.new_chainsetup("default");
[... other setup routines ]
ctrl.start(); // starts processing in another thread (doesn't block)
--cut--
 
\end{verbatim} 


If you don't want to use threads, you can do as above, but use
ECA\_PROCESSOR directly to do the actual processing. In other words, 
you only use ECA\_CONTROL for setting up a ECA\_SESSION object. This 
way the processing is done without additional threads. Here's a 
short sample:

\begin{verbatim} 

--cut--
ECA_SESSION esession;
ECA_CONTROL ctrl (&esession);
ctrl.add_chainsetup("default");
[... other setup routines ]
ECA_PROCESSOR p (&esession);
p.exec(); // blocks until processing is finished
--cut--
 
\end{verbatim} 



\subsection{Ecasound classes as building blocks - {[}C++{]}}
And of course, you can also use individual ecasound classes directly.
This means more control, but it also means more work. Here's
another short sample:

\begin{verbatim} 

--cut--
- create a SAMPLE_BUFFER object for storing the samples
- read samples with an audio I/O object - for example WAVEFILE
- process sample data with some effect class - for example EFFECT_LOWPASS
- maybe change the filter frequency with EFFECT_LOWPASS::set_parameter(1, new_value)
- write samples with an audio I/O object - OSSDEVICE, WAVEFILE, etc.
--cut--
 
\end{verbatim} 





\section{Adding new features and components?}


\subsection{Things to remember when writing new C++ classes}
\subsubsection{Copy constructor and assignment operator}
Always take a moment to check your copy constructor and the assign 
operation (=operation()). Basicly you have three alternatives: 
\begin{itemize}
\item  Trust the automatically created default definitons. If you don't
have any pointers as data members, this isn't necessarily a bad
choice at all. At least the compiler remembers to copy all members!

\item  If you have pointers to objects as class data members, you should
write definitions for both the copy-constructor and the assign
operation.

\item  If you are lazy, just declare the two functions as null
functions, and put them in \_private\_ access scope. At least this way
nobody will use the functions by accident!
\end{itemize}


\subsection{Audio objects}
To implement a new audio object type, you must first select which 
top-level class to derive from. Usually this is either AUDIO\_IO
(the top-level class), AUDIO\_IO\_BUFFERED (a more low level interface)
or AUDIO\_IO\_DEVICE (realtime devices).

The second step is to implement the various virtual functions declared
in the parent classes. These functions can be divided into four
categories: 1) attributes (describes the object and its capabilities), 
2) configuration (routines used for setting up the object), 3) main 
functionality (open, close, input, output, etc) and 4) runtime
information (status info).

Adding the new object to ecasound is much like adding a new effect
(see the next section). Basicly you just add it to the makefiles and
then register it to the appropriate object map (see below).


\subsection{Effects and other chain operators}
Write a new class that inherits from CHAIN\_OPERATOR or any of its
successors. Implement the necessary routines (init, set/get\_parameter, 
process and a default constructor) and add your source files to
libecasound's makefiles. Then all that's left to do is to add your
effect to \emph{libecasound/eca-static-object-maps.cpp},
\emph{register\_default\_objects()}. Now the new effect can be used just 
like any other ecasound effect (parameters control, effect presets, etc).

Another way to add effects to ecasound is to write them as LADSPA
plugins. The API is well documented and there's plenty of
example code available. See \texttt{www.ladspa.org} 
for more information.


\subsection{Differences between audio objects and chain operators}
Design-wise, audio objects and effects (chain operators) aren't that 
far away from each other. Many audio apps don't separate these
concepts at all (for instance most UG based synthesizers). In ecasound 
though, there are some differences:

Input/output:
\begin{itemize}
\item  audio objects can be opened for reading writing or read\&write
\item  effects are modeless
\item  audio objects read from, or write to a buffer
\item  effects get a buffer which they operate (in-place processing)
\end{itemize}

Audio format:
\begin{itemize}
\item  audio objects have a distinct audio format (sample rate, bits,
     channels)
\item  effects should be capable of accepting audio data in any format
     (this is usually easy as ecasound converts all input data to its
     internal format)
\end{itemize}

Control:
\begin{itemize}
\item  audio objects can be opened, closed, prepared, started and stopped
\item  effects don't have a running state
\end{itemize}

Position:
\begin{itemize}
\item  audio objects have length and position attributes
\item  effects just process buffers and don't know about their position
\end{itemize}

A good example of the similarity between the two types are LADSPA
oscillator plugins. Although they are effects, you can easily use them 
as audio inputs by specifying:

\begin{verbatim} 

"ecasound -i null -o /dev/dsp -el:sine_fcac,440,1"
 
\end{verbatim} 



\subsection{LADSPA plugins}
Ecasound supports LADSPA-effect plugins (Linux Audio Developer's Simple
Plugin API). See \texttt{LAD mailing list web site} for 
more info about LADSPA. Other useful sites are 
\texttt{LADSPA home page} and
\texttt{LADSPA documentation}.


\end{document}