




<insert file=../../es-makrot.txt>
<insert name=ecasound_subindexbar>

<hr>
<p>
<center><h2>Ecasound documentation - Programmer's guide</h2></center>
</p>




<html><head><link rev="made" href="mailto:kaiv@wakkanet.fi">
</head>
<body>

<hr>

<h2>Kai Vehmanen</h2>
<h2>07022001</h2>

<h1>Table of Contents </h1><p></p>
<dl><p>
<dt><h2><a href="programmers_guide.html#l1">1: Preface</a></h2>
<dt><h2><a href="programmers_guide.html#l2">2: General guidelines</a></h2>
<dl><p>
<dt><h3><a href="programmers_guide.html#l3">2.1: Design and programming</a></h3>
<dl><p>
<dt><a href="programmers_guide.html#l4">2.1.1: Open and generic design</a>
<dt><a href="programmers_guide.html#l5">2.1.2: Object-orientation</a>
<dt><a href="programmers_guide.html#l6">2.1.3: Data hiding</a>
<dt><a href="programmers_guide.html#l7">2.1.4: Design by contract</a>
<dt><a href="programmers_guide.html#l8">2.1.5: Routine side effects</a>
<dt><a href="programmers_guide.html#l9">2.1.6: Sanity checks</a>
<dt><a href="programmers_guide.html#l10">2.1.7: Error handling</a>
</dl><p>
<dt><h3><a href="programmers_guide.html#l11">2.2: Coding style</a></h3>
<dl><p>
<dt><a href="programmers_guide.html#l12">2.2.1: General guide lines</a>
<dt><a href="programmers_guide.html#l13">2.2.2: Package specific</a>
</dl><p>
<dt><h3><a href="programmers_guide.html#l14">2.3: Physical level organization</a></h3>
<dl><p>
<dt><a href="programmers_guide.html#l15">2.3.1: Distribution packages</a>
<dt><a href="programmers_guide.html#l16">2.3.2: Directories</a>
<dt><a href="programmers_guide.html#l17">2.3.3: File groups</a>
</dl><p>
<dt><h3><a href="programmers_guide.html#l18">2.4: Documentation style</a></h3>
<dt><h3><a href="programmers_guide.html#l19">2.5: Versioning</a></h3>
</dl><p>
<dt><h2><a href="programmers_guide.html#l20">3: How ecasound works?</a></h2>
<dl><p>
<dt><h3><a href="programmers_guide.html#l21">3.1: Common use-cases</a></h3>
<dl><p>
<dt><a href="programmers_guide.html#l22">3.1.1: Simple non-interactive processing</a>
<dt><a href="programmers_guide.html#l23">3.1.2: Multitrack mixing</a>
<dt><a href="programmers_guide.html#l24">3.1.3: Realtime effect processing</a>
<dt><a href="programmers_guide.html#l25">3.1.4: One-track recording</a>
<dt><a href="programmers_guide.html#l26">3.1.5: Multitrack recording</a>
<dt><a href="programmers_guide.html#l27">3.1.6: Recycling a signal through external devices</a>
</dl><p>
<dt><h3><a href="programmers_guide.html#l28">3.2: Signal flow</a></h3>
<dt><h3><a href="programmers_guide.html#l29">3.3: Control flow</a></h3>
<dl><p>
<dt><a href="programmers_guide.html#l30">3.3.1: Passive operation</a>
<dt><a href="programmers_guide.html#l31">3.3.2: Interactive operation</a>
</dl><p>
<dt><h3><a href="programmers_guide.html#l32">3.4: Class descriptions</a></h3>
<dl><p>
<dt><a href="programmers_guide.html#l33">3.4.1: Core</a>
<dt><a href="programmers_guide.html#l34">3.4.2: Data objects</a>
<dt><a href="programmers_guide.html#l35">3.4.3: Object maps</a>
</dl><p>
</dl><p>
<dt><h2><a href="programmers_guide.html#l36">4: Using ecasound from other programs</a></h2>
<dl><p>
<dt><h3><a href="programmers_guide.html#l37">4.1: Console mode ecasound - [all languages]</a></h3>
<dt><h3><a href="programmers_guide.html#l38">4.2: Ecasound Control Interface - [C++, C, Python]</a></h3>
<dt><h3><a href="programmers_guide.html#l39">4.3: Libecasound's ECA_CONTROL class - [C++]</a></h3>
<dt><h3><a href="programmers_guide.html#l40">4.4: Ecasound classes as building blocks - [C++]</a></h3>
</dl><p>
<dt><h2><a href="programmers_guide.html#l41">5: Adding new features and components?</a></h2>
<dl><p>
<dt><h3><a href="programmers_guide.html#l42">5.1: Things to remember when writing new C++ classes</a></h3>
<dl><p>
<dt><a href="programmers_guide.html#l43">5.1.1: Copy constructor and assignment operator</a>
</dl><p>
<dt><h3><a href="programmers_guide.html#l44">5.2: Audio objects</a></h3>
<dt><h3><a href="programmers_guide.html#l45">5.3: Effects and other chain operators</a></h3>
<dt><h3><a href="programmers_guide.html#l46">5.4: Differences between audio objects and chain operators</a></h3>
<dt><h3><a href="programmers_guide.html#l47">5.5: LADSPA plugins</a></h3>
</dl><p>
 
<p><hr><p><br>
<p>

<a name="l1"></a>
<h2>1: Preface</h2>
This document describes how ecasound library works, how to use it,
how to extend and add features to it and so on. Before reading this
document, you should first look at other available documentation
(especially <a href="../users_guide/users_guide.html">ecasound users's guide</a>).
<p>Unlike most web pages, this document really is under construction. :)
<p>

<a name="l2"></a>
<h2>2: General guidelines</h2>
<p>
<a name="l3"></a>
<h3>2.1: Design and programming</h3>
<a name="l4"></a>
<strong>2.1.1: Open and generic design</strong><p>
Over the years ecasound's core design has been revised many times.
After rewriting some code sections hundreds of times, you start
to appreciate genericity. :) Although specific use-cases are used
for testing new ideas, they are just design aids.
<p><a name="l5"></a>
<strong>2.1.2: Object-orientation</strong><p>
Ecasound is written in C++ (as specified in 1997 ANSI/ISO C++ standard). 
Because C++ language itself doesn't force you to follow OO-principles, 
I often use Eiffel language as a reference when designing classes and 
routines.
<p><a name="l6"></a>
<strong>2.1.3: Data hiding</strong><p> 
This OO-feature deserves to be mentioned separately. Whenever 
possible, I always try to hide the actual data representation. 
This allows you to make local implementation changes without
affecting other parts of the code base. One thing I've especially 
tried to avoid is excessive use of pointer magic.
<p><a name="l7"></a>
<strong>2.1.4: Design by contract</strong><p> 
Design by contract means that when you write a new routine,
in addition to the actual code, you also describe routine's 
behaviour as accurately as possible.
<p>Routine must specify all requirements and assumptions. 
If the caller violates this specification, routine is not 
responsible for the error. This means that routine mustn't
check argument validity. This must be done by the caller.
<p>Routine should also specify, what conditions are true when
returning to the caller. By doing this, routine ensures that
it works correctly and calling routine knows what has been
done.
<p>Ideally, these conditions prove that the routine works correctly. 
The benefits of this approach should be clear. When you call 
a well-defined routine, a) you know what parameter values it 
accepts, b) you know what it does and c) if errors occur, 
it's easier to pinpoint the faulty routine. In practice this is 
done by using comments and pre/postconditions. As C++ doesn't 
directly support pre/postconditions, I've simulated them using
the class DEFINITION_BY_CONTRACT from kvutils package and with 
standard assert() calls.
<p><a name="l8"></a>
<strong>2.1.5: Routine side effects</strong><p> 
I try to make a clear distinction between routines that 
have side-effects (=methods, processors, modifiers; routines that
change object's state) and const routines (=functions, observers).
<p><a name="l9"></a>
<strong>2.1.6: Sanity checks</strong><p>
Sanity checks are done only to prevent crashes. All effects
and operators happily accept "insane" parameters. For instance 
you can give -100.0% to the amplifier effect. This of course 
results in inverted sample data. I think this a reasonable 
approach. After all, ecasound is supposed to be a tool for creative
work and experimenting. It's not meant for e-commerce. ;)
<p><a name="l10"></a>
<strong>2.1.7: Error handling</strong><p>
Two specific things worth mentioning: First, the standard UNIX-style 
error handling, where functions performing actions return an integer 
value, is <em>not</em> used in ecasound. As described in the above section 
<em>Routine side effects</em>, all routines are either modifiers or
observers, not both. So when using ecasound APIs, you first perform an
action (modifying function), and then afterwards check what happened
(using an observer function).
<p>Secondly, C++ exceptions are used in ecasound. Exception based error
handling has its problems, but in some cases it is clearly the best
option. Using exceptions for anything other than pure exception
handling is to be avoided at all cost. And when exceptions are used,
their use must be specified in function prototypes. This is important,
as clients need to know what exceptions can be thrown. All in all, use 
of exceptions should be carefully planned.
<p>
<a name="l11"></a>
<h3>2.2: Coding style</h3>
<a name="l12"></a>
<strong>2.2.1: General guide lines</strong><p>
Variable names are all lower case and words are separated with
underscores (int very_long_variable_name_with_underscores). Class data
members are marked with <em>_rep</em> postfix. Data members which are
pointers are marked with <em>_repp</em>. Index-style short variable names 
(<em>n</em>, <em>m</em>, etc.) are only used in local scopes. Enum types 
have capitalized names (<em>Some_enum</em>).
<p><a name="l13"></a>
<strong>2.2.2: Package specific</strong><p>
<dl>
<p></p><dt><strong>libecasound, ecasound, ecatools, libkvutils</strong><dd>
Class names are all in upper case and words separated with underscores
(class ECA_CONTROL_BASE). This a standard style in Eiffel programming.
<p><p></p><dt><strong>libqtecasound, qtecasound, ecawave</strong><dd>
Qt-style is used when naming classes (class QELevelMeter), otherwise
same as above.
</dl>
<p>
<a name="l14"></a>
<h3>2.3: Physical level organization</h3>
Ecasound libraries and applications are divided into <em>distribution 
packages</em>, <em>directories</em> and <em>file groups</em>. 
<p><a name="l15"></a>
<strong>2.3.1: Distribution packages</strong><p>
As an example, <em>ecasound</em> and <em>qtecasound</em> are distributed as separate
packages. This decision has been made because a) they are clearly 
independent, b) they have different external dependencies, and c)
they address different target uses. 
<p><a name="l16"></a>
<strong>2.3.2: Directories</strong><p>
It's convenient to organize larger sets of source code into separate
directories. For instance in ecasound, <em>libecasound</em> and
<em>ecatools</em> are in two separate directories.
<p><a name="l17"></a>
<strong>2.3.3: File groups</strong><p>
Although files are divided in directories and subdirectories, 
there's still a need to logically group a set of source files based
on their use and role in the overall design. As the use of C++ 
namespaces is very limited in ecasound (to avoid portability
problems), filename prefixes are used for grouping files. Here's
a short list of commonly used prefixes. 
<p><dl>
<p></p><dt><strong>audioio*.{cpp,h}</strong><dd> 
Audio device and file input/output.
<p></p><dt><strong>audiofx*.{cpp,h}</strong><dd> 
Audio effects and other DSP-related code.
<p></p><dt><strong>audiogate*.{cpp,h}</strong><dd> 
Gate operators.
<p></p><dt><strong>eca-*.{cpp,h}</strong><dd> 
Core functionality.
<p></p><dt><strong>midi-*.{cpp,h}</strong><dd> 
MIDI input/output devices, handlers and controller code.
<p></p><dt><strong>osc-*.{cpp,h}</strong><dd> 
Oscillator and other controller sources.
<p></p><dt><strong>qe*.{cpp,h}</strong><dd> 
Generic prefix for files utilizing both Qt and ecasound libraries.
<p></p><dt><strong>samplebuffer-*.{cpp,h}</strong><dd> 
Routines and helper functions for processing audio data buffers.
</dl>
<p>You should note that these are just recommendations - there are no
strict rules on how files should be named.
<p>
<a name="l18"></a>
<h3>2.4: Documentation style</h3>
Javadoc-style class documentation is the preferred style.
Class members can be documented either when they are declared (header
files), or when they are defined. Especially when specifying
complicated interfaces, it's better to put documentation in the
definition files. This way the header files remain compact and serve 
better as a reference. 
<p>Here's a few general documentation guide lines:
<dl>
<p></p><dt><strong>Use of 3rd person</strong><dd> 
"Writes samples to memory." instead of "Write samples to memory."
<p></p><dt><strong>Sentences start with a verb</strong><dd>
"Writes samples to memory." instead of "Samples are written to memory."
<p></p><dt><strong>This instead of the</strong><dd>
"Get controllers connected to this effect." instead of "Get controllers connected to the effect.
</dl>
<p>
<a name="l19"></a>
<h3>2.5: Versioning</h3>
All ecasound releases have a distinct version number. To emphasize the
difference between stable and development releases, devel versions are 
marked with 'devXX'. For instance, you could have development 
releases 0.1dev1, 0.1dev2 and 0.1dev3. When the development reaches 
a stable status, 0.1 is be released. After this, a new development 
series will start (0.2dev1, and so on).
<p>Separation between development and stable releases is very important,
because it affects library versioning. The idea is that all library
interfaces are versioned separately with libtool. If during
development changes are made to the public interfaces, a new interface
version is created. The new interface version won't be frozen until the 
next stable version. After this, no changes to the interface (affects
both at binary and source level) are allowed. If these changes must be 
made, a new interface version must be created. It's important to note
that interface compatibility is not guaranteed between development
releases. So if you are linking apps against development versions of
ecasound libraries, you must be prepared for interface changes.
<p>All changes in the public interfaces are documented in library
specific <em>ChangeLog</em> files. These files are usually located in the
top-level source directory.
<p>

<a name="l20"></a>
<h2>3: How ecasound works?</h2>
<p>
<a name="l21"></a>
<h3>3.1: Common use-cases</h3>
Here's some common cases how ecasound can be used.
<p><a name="l22"></a>
<strong>3.1.1: Simple non-interactive processing</strong><p>
One input is processed and then written to one output. This includes effect 
processing, normal sample playback, format conversions, etc.
<p><a name="l23"></a>
<strong>3.1.2: Multitrack mixing</strong><p>
Multiple inputs are mixed into one output.
<p><a name="l24"></a>
<strong>3.1.3: Realtime effect processing</strong><p>
There's at least one realtime input and one realtime output.
Signal is sampled from the realtime input, processed and
written to the realtime output.
<p><a name="l25"></a>
<strong>3.1.4: One-track recording</strong><p>
One input is processed and written to one or more outputs.
<p><a name="l26"></a>
<strong>3.1.5: Multitrack recording</strong><p>
The most common situation is that there are two separate
chains. First one consists of realtime input routed to a
non-realtime output. This is the recording chain. The
other one is the monitor chain and it consists of one or
more non-realtime inputs routed to a realtime output.
You could also route your realtime input to the monitoring
chain, but this is not recommended because of severe
timing problems. To synchronize these two separate chains,
ecasound uses a special multitrack mode (which should be
enabled automatically).
<p><a name="l27"></a>
<strong>3.1.6: Recycling a signal through external devices</strong><p>
Just like multirack recording. The only difference is
that realtime input and output are externally
connected.
<p>
<a name="l28"></a>
<h3>3.2: Signal flow</h3>
This is simple. A group of inputs is routed to a group of chains.
Audio data is processed in the chains and afterwards routed to 
a group of outputs. Using internal loop devices, it' also possible to 
route signals from one chain to another. It's also possible to assign
inputs and outputs to multiple chains.
<p>
<a name="l29"></a>
<h3>3.3: Control flow</h3>
<a name="l30"></a>
<strong>3.3.1: Passive operation</strong><p>
When ecasound is run in passive mode, the program flow is simple.
A ECA_SESSION object is created with suitable parameters, it is
passed to a ECA_PROCESSOR object and that is all. Once engine
is started, it does the processing and exits. 
<p>Another way to do passive processing is to create a ECA_CONTROL 
object and use it to to access and modify the ECA_SESSION object 
before passing it to ECA_PROCESSOR.
<p><a name="l31"></a>
<strong>3.3.2: Interactive operation</strong><p>
In interactive mode, everything is done using the interface provided
by ECA_CONTROL. This is when things get complex:
<p>ECA_SESSION object can contain many ECA_CHAINSETUP objects, but
only one of them can be active. On the other hand it is possible
that there are no chainsetups. If this is the case, about the
only thing you can do is to add a new chainsetup. 
<p>When some chainsetup is activated, it can be edited using the
interface provided by ECA_CONTROL. Before actual processing can
start, the chainsetup must first be connected. Only valid 
chainsetups (at least one input-output pair connected to the same
chain) can be connected. 
<p><dl>
ECA_CHAINSETUP can be...
<dl>
<p><p></p><dt><strong>not selected</strong><dd> - can't be accessed from ECA_PROCESSOR
<p></p><dt><strong>selected, invalid</strong><dd> - can be edited (files and devices are not opened)
<p></p><dt><strong>selected, valid</strong><dd> - can be connected (files and devices are not opened)
<p></p><dt><strong>connected</strong><dd> - ready for processing (files and devices are opened before connecting)
<p></dl>
</dl>
<p><dl>
ECA_PROCESSOR status is one of...
<dl>
<p><p></p><dt><strong>not_ready</strong><dd> - ECA_SESSION object is not ready for processing or
ECA_PROCESSOR hasn't been created
<p></p><dt><strong>running</strong><dd> - processing
<p></p><dt><strong>stopped</strong><dd> - processing hasn't been started or it has been stopped
before completion
<p></p><dt><strong>finished</strong><dd> - processing has been completed
<p></dl>
</dl>
<p>
<a name="l32"></a>
<h3>3.4: Class descriptions</h3>
<p>The primary source for class documentation is header files.
A browsable version of header documentation is at
<a href="http://www.wakkanet.fi/~kaiv/ecasound/Documentation/doxygen_pages.html">www.wakkanet.fi/~kaiv/ecasound/Documentation/doxygen_pages.html</a>
Anyway, let's look at the some central classes.
<p>
<a name="l33"></a>
<strong>3.4.1: Core</strong><p> 
<p><strong>ECA_PROCESSOR</strong><br><br> 
ECA_PROCESSOR is the actual processing engine. It is initialized with
a pointer to a ECA_SESSION object, which has all information needed at
runtime. Processing is started with the exec() member function and
after that, ECA_PROCESSOR runs on its own. If the interactive mode is
enabled in ECA_SESSION, ECA_PROCESSOR can be controlled using the
ECA_CONTROL class. It offers a safe way to control ecasound.
Another way to communicate with ECA_PROCESSOR is to access the
ECA_SESSION object directly.
<p><p><strong>ECA_SESSION</strong><br><br> 
ECA_SESSION represents the data used by ecasound. A session contains
all ECA_CHAINSETUP objects and general runtime settings (iactive-mode,
debug-level, etc). Only one ECA_CHAINSETUP can be active at a time. To
make it easier to control how threads access ECA_SESSION, only
ECA_PROCESSOR and ECA_CONTROL classes have direct access to
ECA_SESSION data and functions. Other classes can only use <em>const</em>
members of ECA_SESSION. 
<p><p><strong>ECA_CONTROL</strong><br><br> 
ECA_CONTROL represents the whole public interface offered by 
ecasound library. It also has a simple command interpreter 
(interactive-mode) that can used for controlling ecasound. 
<p>
<a name="l34"></a>
<strong>3.4.2: Data objects</strong><p>
<p><p><strong>SAMPLEBUFFER</strong><br><br>
Basic unit for representing sample data. The data type used to 
represent a single sample, valid value range, channel count, global 
sampling rate and system endianess are all specified in 
"samplebuffer.h" and "sample_specs.h".
<p><p><strong>DEBUG</strong><br><br>
Virtual interface class for the debugging subsystem. Ecasound engine 
sends all debug messages to an instance of this class. The actual 
implementation can be done in many ways. For example in the console mode
user-interface  of ecasound, TEXTDEBUG class is used to implement the DEBUG
interface. It sends all messages that have a suitable debug 
level to the standard output stream. On the other hand, in qtecasound 
DEBUG is implemented using a Qt widget. New DEBUG implementations can
be registered at runtime with the <em>attach_debug_object()</em> call
(declared in eca-debug.h).
<p>
<a name="l35"></a>
<strong>3.4.3: Object maps</strong><p>
Object maps are a central repositories for commonly used objects.
When object is registered to a map, a regular expression is attached 
to it. When object map receives a request for a new object, it 
goes through all registered regular expressions, and returns an 
object attached to the matching expression. Object maps can also provide
a list of all registered objects. 
<p>This system may sound a bit complex, but in practise it is quite
simple and makes a lot of things more easier. For instance, when
adding new object types to the library, you only have to add a call
which registers the new object; no need to modify any other part of 
the library. It also makes it possible to add new types at runtime. For
instance, an application linked against libecasound might add its own
custom object types on startup. All parts of libecasound can use the
custom objects, although they are not part of library itself.
<p>All objects defined in libecasound are registered in the file
<em>eca-static-object-maps.cpp</em>.
<p><p><strong>ECA_OBJECT</strong><br><br>
A virtual base class that represents one object. All classes deriving 
from ECA_OBJECT can be registered to object maps.
<p><p><strong>ECA_OBJECT_MAP</strong><br><br>
This is the basic object map implementation. It offers map services
for ECA_OBJECT objects.
<p><p><strong>ECA_PRESET_MAP</strong><br><br>
Special class that inherits from ECA_OBJECT_MAP. This class is used
for mapping instances of class PRESET.
<p><p><strong>ECA_AUDIO_OBJECT_MAP</strong><br><br>
A convenience class for mapping AUDIO_IO objects. Handles the casting 
between ECA_OBJECT&lt;-&gt;AUDIO_IO.
<p><p><strong>ECA_CHAIN_OPERATOR_MAP</strong><br><br>
A convenience class for mapping CHAIN_OPERATOR objects. Handles the casting 
between ECA_OBJECT&lt;-&gt;CHAIN_OPERATOR.
<p><p><strong>ECA_CONTROLLER_MAP</strong><br><br>
A convenience class for mapping GENERIC_CONTROLLER objects. Handles the casting 
between ECA_OBJECT&lt;-&gt;GENERIC_CONTROLLER.
<p><p><strong>ECA_LADSPA_PLUGIN_MAP</strong><br><br>
A convenience class for mapping EFFECT_LADSPA objects. Handles the casting 
between ECA_OBJECT&lt;-&gt;EFFECT_LADSPA.
<p>

<p><a name="l36"></a>
<h2>4: Using ecasound from other programs</h2>
<p>
<a name="l37"></a>
<h3>4.1: Console mode ecasound - [all languages]</h3>
This is the easiest way to take advantage of ecasound features in your
own programs. You can fork ecasound, pipe commands to ecasound's
interactive mode or you can create chainsetup (.ecs) files and load
them to ecasound. You'll be able to do practically anything. The only 
real problem is getting information from ecasound. You'll have to
parse ecasound's ascii output if you want to do this. To make this 
a bit easier, ecasound offers the dump-* commands. These print
configuration and status info as formatted text strings (easier to
parse than normal output).
<p>
<a name="l38"></a>
<h3>4.2: Ecasound Control Interface - [C++, C, Python]</h3>
<p>Idea behind Ecasound Control Interface (ECI) is to take a subset of 
functionality provided by libecasound, write a simple API for it, and
port it to various languages. At the moment, at least C++, C and
Python implementations of the ECI API are available and part of the
main ecasound distribution. ECI is heavily based on ecasound's
interactive mode (EIAM), and the services it provides. 
<p>Specific tasks ECI is aimed at:
<p><dl>
<li > 1. automating (scripting in its traditional sense)
<li > 2. frontends (generic / specialized)
<li > 3. sound services to other apps
</dl>
<p>
<a name="l39"></a>
<h3>4.3: Libecasound's ECA_CONTROL class - [C++]</h3>
By linking your program to libecasound, you can use the ECA_CONTROL
class for controlling ecasound. This is a large interface class that
offers routines for controlling all ecasound features. It's easy
to use while still powerful. Best examples are the utils in ecatools 
directory (most of them are just a couple screenfuls of code). Also, 
qtecasound and ecawave heavily use ECA_CONTROL. Here's a few lines of 
example code:
<p><pre>

--cut--
ECA_SESSION esession;
ECA_CONTROL ctrl (&amp;esession);
ctrl.new_chainsetup("default");
[... other setup routines ]
ctrl.start(); // starts processing in another thread (doesn't block)
--cut--

</pre>

<p>If you don't want to use threads, you can do as above, but use
ECA_PROCESSOR directly to do the actual processing. In other words, 
you only use ECA_CONTROL for setting up a ECA_SESSION object. This 
way the processing is done without additional threads. Here's a 
short sample:
<p><pre>

--cut--
ECA_SESSION esession;
ECA_CONTROL ctrl (&amp;esession);
ctrl.add_chainsetup("default");
[... other setup routines ]
ECA_PROCESSOR p (&amp;esession);
p.exec(); // blocks until processing is finished
--cut--

</pre>

<p>
<a name="l40"></a>
<h3>4.4: Ecasound classes as building blocks - [C++]</h3>
And of course, you can also use individual ecasound classes directly.
This means more control, but it also means more work. Here's
another short sample:
<p><pre>

--cut--
- create a SAMPLE_BUFFER object for storing the samples
- read samples with an audio I/O object - for example WAVEFILE
- process sample data with some effect class - for example EFFECT_LOWPASS
- maybe change the filter frequency with EFFECT_LOWPASS::set_parameter(1, new_value)
- write samples with an audio I/O object - OSSDEVICE, WAVEFILE, etc.
--cut--

</pre>

<p>

<p><a name="l41"></a>
<h2>5: Adding new features and components?</h2>
<p>
<a name="l42"></a>
<h3>5.1: Things to remember when writing new C++ classes</h3>
<a name="l43"></a>
<strong>5.1.1: Copy constructor and assignment operator</strong><p>
Always take a moment to check your copy constructor and the assign 
operation (=operation()). Basicly you have three alternatives: 
<dl>
<li > Trust the automatically created default definitons. If you don't
have any pointers as data members, this isn't necessarily a bad
choice at all. At least the compiler remembers to copy all members!
<p><li > If you have pointers to objects as class data members, you should
write definitions for both the copy-constructor and the assign
operation.
<p><li > If you are lazy, just declare the two functions as null
functions, and put them in _private_ access scope. At least this way
nobody will use the functions by accident!
</dl>
<p>
<a name="l44"></a>
<h3>5.2: Audio objects</h3>
To implement a new audio object type, you must first select which 
top-level class to derive from. Usually this is either AUDIO_IO
(the top-level class), AUDIO_IO_BUFFERED (a more low level interface)
or AUDIO_IO_DEVICE (realtime devices).
<p>The second step is to implement the various virtual functions declared
in the parent classes. These functions can be divided into four
categories: 1) attributes (describes the object and its capabilities), 
2) configuration (routines used for setting up the object), 3) main 
functionality (open, close, input, output, etc) and 4) runtime
information (status info).
<p>Adding the new object to ecasound is much like adding a new effect
(see the next section). Basicly you just add it to the makefiles and
then register it to the appropriate object map (see below).
<p>
<a name="l45"></a>
<h3>5.3: Effects and other chain operators</h3>
Write a new class that inherits from CHAIN_OPERATOR or any of its
successors. Implement the necessary routines (init, set/get_parameter, 
process and a default constructor) and add your source files to
libecasound's makefiles. Then all that's left to do is to add your
effect to <em>libecasound/eca-static-object-maps.cpp</em>,
<em>register_default_objects()</em>. Now the new effect can be used just 
like any other ecasound effect (parameters control, effect presets, etc).
<p>
<a name="l46"></a>
<h3>5.4: Differences between audio objects and chain operators</h3>
Design-wise, audio objects and effects (chain operators) aren't that 
far away from each other. Many audio apps don't separate these
concepts at all (for instance most UG based synthesizers). In ecasound 
though, there are some differences:
<p>Input/output:
<dl>
<li > audio objects can be opened for reading writing or read&amp;write
<li > effects are modeless
<li > audio objects read from, or write to a buffer
<li > effects get a buffer which they operate (in-place processing)
</dl>
<p>Audio format:
<dl>
<li > audio objects have a distinct audio format (sample rate, bits,
     channels)
<li > effects should be capable of accepting audio data in any format
     (this is usually easy as ecasound converts all input data to its
     internal format)
</dl>
<p>Control:
<dl>
<li > audio objects can be opened, closed, prepared, started and stopped
<li > effects don't have a running state
</dl>
<p>Position:
<dl>
<li > audio objects have length and position attributes
<li > effects just process buffers and don't know about their position
</dl>
<p>A good example of the similarity between the two types are LADSPA
oscillator plugins. Although they are effects, you can easily use them 
as audio inputs by specifying:
<p><pre>

"ecasound -i null -o /dev/dsp -el:sine_fcac,440,1"

</pre>

<p>
<a name="l47"></a>
<h3>5.5: LADSPA plugins</h3>
Ecasound supports LADSPA-effect plugins (Linux Audio Developer's Simple
Plugin API). See <a href="http://www.linuxdj.com/audio/lad">LAD mailing list web site</a> for 
more info about LADSPA. Other useful sites are 
<a href="http://www.ladspa.org">LADSPA home page</a> and
<a href="http://www.ffem.org/gdam/ladspa-doc/ladspa.html">LADSPA documentation</a>.
<p><insert name=ecasound_tail>
</body>
</html>
